{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mcORpolNoZoI",
        "outputId": "3d5569a5-e693-4d41-cb86-3e9877674240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for default config on: /content/tinytroupe/tinytroupe/utils/../config.ini\n",
            "Failed to find custom config on: /content/tinytroupe/config.ini\n",
            "Will use only default values. IF THINGS FAIL, TRY CUSTOMIZING MODEL, API TYPE, etc.\n",
            "\n",
            "!!!!\n",
            "DISCLAIMER: TinyTroupe relies on Artificial Intelligence (AI) models to generate content. \n",
            "The AI models are not perfect and may produce inappropriate or inacurate results. \n",
            "For any serious or consequential use, please review the generated content before using it.\n",
            "!!!!\n",
            "\n",
            "\n",
            "=================================\n",
            "Current TinyTroupe configuration \n",
            "=================================\n",
            "[OpenAI]\n",
            "api_type = openai\n",
            "azure_api_version = 2023-05-15\n",
            "model = gpt-4o-mini\n",
            "max_tokens = 4000\n",
            "temperature = 1.2\n",
            "freq_penalty = 0.0\n",
            "presence_penalty = 0.0\n",
            "timeout = 60\n",
            "max_attempts = 5\n",
            "waiting_time = 1\n",
            "exponential_backoff_factor = 5\n",
            "embedding_model = text-embedding-3-small\n",
            "cache_api_calls = False\n",
            "cache_file_name = openai_api_cache.pickle\n",
            "max_content_display_length = 1024\n",
            "\n",
            "[Simulation]\n",
            "rai_harmful_content_prevention = True\n",
            "rai_copyright_infringement_prevention = True\n",
            "\n",
            "[Logging]\n",
            "loglevel = ERROR\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;4;38;5;51mUSER\u001b[0m\u001b[1;3;38;5;51m --> \u001b[0m\u001b[1;3;4;38;5;51mRakesh\u001b[0m\u001b[1;3;38;5;51m: \u001b[0m\u001b[1;3;38;5;51m[\u001b[0m\u001b[1;3;38;5;51mCONVERSATION\u001b[0m\u001b[1;3;38;5;51m]\u001b[0m\u001b[1;3;38;5;51m \u001b[0m\n",
              "\u001b[1;3;38;5;51m          > What are the key challenges in deploying machine learning models at scale?\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">USER</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\"> --&gt; </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">Rakesh</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">: [CONVERSATION] </span>\n",
              "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">          &gt; What are the key challenges in deploying machine learning models at scale?</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[4;32mRakesh\u001b[0m\u001b[32m acts: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32mTHINK\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m \u001b[0m\n",
              "\u001b[32m            > The key challenges in deploying machine learning models at scale include data quality,\u001b[0m\n",
              "\u001b[32m            > model performance, infrastructure requirements, and ongoing maintenance. I need to\u001b[0m\n",
              "\u001b[32m            > articulate these points clearly.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">Rakesh</span><span style=\"color: #008000; text-decoration-color: #008000\"> acts: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">THINK</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; The key challenges in deploying machine learning models at scale include data quality,</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; model performance, infrastructure requirements, and ongoing maintenance. I need to</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; articulate these points clearly.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;4;38;5;40mRakesh\u001b[0m\u001b[1;38;5;40m acts: \u001b[0m\u001b[1;38;5;40m[\u001b[0m\u001b[1;38;5;40mTALK\u001b[0m\u001b[1;38;5;40m]\u001b[0m\u001b[1;38;5;40m \u001b[0m\n",
              "\u001b[1;38;5;40m            > There are several key challenges in deploying machine learning models at scale. First,\u001b[0m\n",
              "\u001b[1;38;5;40m            > ensuring data quality is crucial, as poor data can lead to inaccurate predictions.\u001b[0m\n",
              "\u001b[1;38;5;40m            > Second, maintaining model performance over time can be difficult, especially as data\u001b[0m\n",
              "\u001b[1;38;5;40m            > distributions change. Third, the infrastructure needed to support large-scale\u001b[0m\n",
              "\u001b[1;38;5;40m            > deployments can be complex and costly. Finally, ongoing maintenance and monitoring of\u001b[0m\n",
              "\u001b[1;38;5;40m            > the models are essential to ensure they continue to perform well. Would you like to\u001b[0m\n",
              "\u001b[1;38;5;40m            > discuss any specific challenge in more detail?\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold; text-decoration: underline\">Rakesh</span><span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\"> acts: [TALK] </span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; There are several key challenges in deploying machine learning models at scale. First,</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; ensuring data quality is crucial, as poor data can lead to inaccurate predictions.</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; Second, maintaining model performance over time can be difficult, especially as data</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; distributions change. Third, the infrastructure needed to support large-scale</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; deployments can be complex and costly. Finally, ongoing maintenance and monitoring of</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; the models are essential to ensure they continue to perform well. Would you like to</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; discuss any specific challenge in more detail?</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[4;38;5;252mRakesh\u001b[0m\u001b[38;5;252m acts: \u001b[0m\u001b[1;38;5;252m[\u001b[0m\u001b[38;5;252mDONE\u001b[0m\u001b[1;38;5;252m]\u001b[0m\u001b[38;5;252m \u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; text-decoration: underline\">Rakesh</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\"> acts: </span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; font-weight: bold\">[</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\">DONE</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; font-weight: bold\">]</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\"> </span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;4;38;5;51mUSER\u001b[0m\u001b[1;3;38;5;51m --> \u001b[0m\u001b[1;3;4;38;5;51mRakesh\u001b[0m\u001b[1;3;38;5;51m: \u001b[0m\u001b[1;3;38;5;51m[\u001b[0m\u001b[1;3;38;5;51mCONVERSATION\u001b[0m\u001b[1;3;38;5;51m]\u001b[0m\u001b[1;3;38;5;51m \u001b[0m\n",
              "\u001b[1;3;38;5;51m          > How do you ensure data quality in large datasets?\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">USER</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\"> --&gt; </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">Rakesh</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">: [CONVERSATION] </span>\n",
              "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">          &gt; How do you ensure data quality in large datasets?</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[4;32mRakesh\u001b[0m\u001b[32m acts: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32mTHINK\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m \u001b[0m\n",
              "\u001b[32m            > To ensure data quality in large datasets, I need to consider several strategies such\u001b[0m\n",
              "\u001b[32m            > as data validation, cleaning, and regular audits. It's important to implement\u001b[0m\n",
              "\u001b[32m            > automated checks and maintain clear documentation.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">Rakesh</span><span style=\"color: #008000; text-decoration-color: #008000\"> acts: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">THINK</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; To ensure data quality in large datasets, I need to consider several strategies such</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; as data validation, cleaning, and regular audits. It's important to implement</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; automated checks and maintain clear documentation.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;4;38;5;40mRakesh\u001b[0m\u001b[1;38;5;40m acts: \u001b[0m\u001b[1;38;5;40m[\u001b[0m\u001b[1;38;5;40mTALK\u001b[0m\u001b[1;38;5;40m]\u001b[0m\u001b[1;38;5;40m \u001b[0m\n",
              "\u001b[1;38;5;40m            > To ensure data quality in large datasets, I focus on several key strategies. First, I\u001b[0m\n",
              "\u001b[1;38;5;40m            > implement data validation techniques to check for errors and inconsistencies. Second,\u001b[0m\n",
              "\u001b[1;38;5;40m            > I perform data cleaning to remove duplicates and correct inaccuracies. Additionally, I\u001b[0m\n",
              "\u001b[1;38;5;40m            > conduct regular audits to monitor data quality over time. Automated checks can also\u001b[0m\n",
              "\u001b[1;38;5;40m            > help in maintaining high standards. Would you like to know more about any specific\u001b[0m\n",
              "\u001b[1;38;5;40m            > method?\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold; text-decoration: underline\">Rakesh</span><span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\"> acts: [TALK] </span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; To ensure data quality in large datasets, I focus on several key strategies. First, I</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; implement data validation techniques to check for errors and inconsistencies. Second,</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; I perform data cleaning to remove duplicates and correct inaccuracies. Additionally, I</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; conduct regular audits to monitor data quality over time. Automated checks can also</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; help in maintaining high standards. Would you like to know more about any specific</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; method?</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[4;38;5;252mRakesh\u001b[0m\u001b[38;5;252m acts: \u001b[0m\u001b[1;38;5;252m[\u001b[0m\u001b[38;5;252mDONE\u001b[0m\u001b[1;38;5;252m]\u001b[0m\u001b[38;5;252m \u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; text-decoration: underline\">Rakesh</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\"> acts: </span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; font-weight: bold\">[</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\">DONE</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; font-weight: bold\">]</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\"> </span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;4;38;5;51mUSER\u001b[0m\u001b[1;3;38;5;51m --> \u001b[0m\u001b[1;3;4;38;5;51mRakesh\u001b[0m\u001b[1;3;38;5;51m: \u001b[0m\u001b[1;3;38;5;51m[\u001b[0m\u001b[1;3;38;5;51mCONVERSATION\u001b[0m\u001b[1;3;38;5;51m]\u001b[0m\u001b[1;3;38;5;51m \u001b[0m\n",
              "\u001b[1;3;38;5;51m          > What are your best practices for feature engineering?\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">USER</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\"> --&gt; </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">Rakesh</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">: [CONVERSATION] </span>\n",
              "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">          &gt; What are your best practices for feature engineering?</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[4;32mRakesh\u001b[0m\u001b[32m acts: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32mTHINK\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m \u001b[0m\n",
              "\u001b[32m            > Best practices for feature engineering include understanding the domain, selecting\u001b[0m\n",
              "\u001b[32m            > relevant features, creating new features through transformations, and evaluating\u001b[0m\n",
              "\u001b[32m            > feature importance. I should prepare to explain these points clearly.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">Rakesh</span><span style=\"color: #008000; text-decoration-color: #008000\"> acts: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">THINK</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; Best practices for feature engineering include understanding the domain, selecting</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; relevant features, creating new features through transformations, and evaluating</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; feature importance. I should prepare to explain these points clearly.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;4;38;5;40mRakesh\u001b[0m\u001b[1;38;5;40m acts: \u001b[0m\u001b[1;38;5;40m[\u001b[0m\u001b[1;38;5;40mTALK\u001b[0m\u001b[1;38;5;40m]\u001b[0m\u001b[1;38;5;40m \u001b[0m\n",
              "\u001b[1;38;5;40m            > When it comes to feature engineering, some best practices include understanding the\u001b[0m\n",
              "\u001b[1;38;5;40m            > domain thoroughly to identify relevant features, selecting features that have a strong\u001b[0m\n",
              "\u001b[1;38;5;40m            > correlation with the target variable, and creating new features through\u001b[0m\n",
              "\u001b[1;38;5;40m            > transformations or combinations of existing ones. It's also important to evaluate\u001b[0m\n",
              "\u001b[1;38;5;40m            > feature importance to understand which features contribute the most to the model's\u001b[0m\n",
              "\u001b[1;38;5;40m            > performance. Would you like to dive deeper into any specific aspect of feature\u001b[0m\n",
              "\u001b[1;38;5;40m            > engineering?\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold; text-decoration: underline\">Rakesh</span><span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\"> acts: [TALK] </span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; When it comes to feature engineering, some best practices include understanding the</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; domain thoroughly to identify relevant features, selecting features that have a strong</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; correlation with the target variable, and creating new features through</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; transformations or combinations of existing ones. It's also important to evaluate</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; feature importance to understand which features contribute the most to the model's</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; performance. Would you like to dive deeper into any specific aspect of feature</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; engineering?</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[4;38;5;252mRakesh\u001b[0m\u001b[38;5;252m acts: \u001b[0m\u001b[1;38;5;252m[\u001b[0m\u001b[38;5;252mDONE\u001b[0m\u001b[1;38;5;252m]\u001b[0m\u001b[38;5;252m \u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; text-decoration: underline\">Rakesh</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\"> acts: </span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; font-weight: bold\">[</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\">DONE</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; font-weight: bold\">]</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\"> </span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;4;38;5;51mUSER\u001b[0m\u001b[1;3;38;5;51m --> \u001b[0m\u001b[1;3;4;38;5;51mRakesh\u001b[0m\u001b[1;3;38;5;51m: \u001b[0m\u001b[1;3;38;5;51m[\u001b[0m\u001b[1;3;38;5;51mCONVERSATION\u001b[0m\u001b[1;3;38;5;51m]\u001b[0m\u001b[1;3;38;5;51m \u001b[0m\n",
              "\u001b[1;3;38;5;51m          > How do you handle model drift in production systems?\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">USER</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\"> --&gt; </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">Rakesh</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">: [CONVERSATION] </span>\n",
              "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">          &gt; How do you handle model drift in production systems?</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[4;32mRakesh\u001b[0m\u001b[32m acts: \u001b[0m\u001b[1;32m[\u001b[0m\u001b[32mTHINK\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m \u001b[0m\n",
              "\u001b[32m            > Handling model drift in production systems involves monitoring model performance over\u001b[0m\n",
              "\u001b[32m            > time, retraining models with new data, and implementing automated alerts for\u001b[0m\n",
              "\u001b[32m            > significant performance drops. I need to articulate these strategies clearly.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">Rakesh</span><span style=\"color: #008000; text-decoration-color: #008000\"> acts: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">THINK</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; Handling model drift in production systems involves monitoring model performance over</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; time, retraining models with new data, and implementing automated alerts for</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">            &gt; significant performance drops. I need to articulate these strategies clearly.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;4;38;5;40mRakesh\u001b[0m\u001b[1;38;5;40m acts: \u001b[0m\u001b[1;38;5;40m[\u001b[0m\u001b[1;38;5;40mTALK\u001b[0m\u001b[1;38;5;40m]\u001b[0m\u001b[1;38;5;40m \u001b[0m\n",
              "\u001b[1;38;5;40m            > To handle model drift in production systems, I focus on several key strategies. First,\u001b[0m\n",
              "\u001b[1;38;5;40m            > I continuously monitor the model's performance to detect any significant drops.\u001b[0m\n",
              "\u001b[1;38;5;40m            > Second, I retrain the model regularly with new data to ensure it remains relevant.\u001b[0m\n",
              "\u001b[1;38;5;40m            > Additionally, I implement automated alerts that notify the team when performance\u001b[0m\n",
              "\u001b[1;38;5;40m            > metrics fall below a certain threshold. This proactive approach helps maintain the\u001b[0m\n",
              "\u001b[1;38;5;40m            > model's accuracy over time. Would you like to explore any specific strategy further?\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold; text-decoration: underline\">Rakesh</span><span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\"> acts: [TALK] </span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; To handle model drift in production systems, I focus on several key strategies. First,</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; I continuously monitor the model's performance to detect any significant drops.</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; Second, I retrain the model regularly with new data to ensure it remains relevant.</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; Additionally, I implement automated alerts that notify the team when performance</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; metrics fall below a certain threshold. This proactive approach helps maintain the</span>\n",
              "<span style=\"color: #00d700; text-decoration-color: #00d700; font-weight: bold\">            &gt; model's accuracy over time. Would you like to explore any specific strategy further?</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[4;38;5;252mRakesh\u001b[0m\u001b[38;5;252m acts: \u001b[0m\u001b[1;38;5;252m[\u001b[0m\u001b[38;5;252mDONE\u001b[0m\u001b[1;38;5;252m]\u001b[0m\u001b[38;5;252m \u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; text-decoration: underline\">Rakesh</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\"> acts: </span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; font-weight: bold\">[</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\">DONE</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0; font-weight: bold\">]</span><span style=\"color: #d0d0d0; text-decoration-color: #d0d0d0\"> </span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;4;38;5;51mUSER\u001b[0m\u001b[1;3;38;5;51m --> \u001b[0m\u001b[1;3;4;38;5;51mRakesh\u001b[0m\u001b[1;3;38;5;51m: \u001b[0m\u001b[1;3;38;5;51m[\u001b[0m\u001b[1;3;38;5;51mCONVERSATION\u001b[0m\u001b[1;3;38;5;51m]\u001b[0m\u001b[1;3;38;5;51m \u001b[0m\n",
              "\u001b[1;3;38;5;51m          > What strategies do you use for optimizing deep learning models?\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"margin:0px;;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">USER</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\"> --&gt; </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic; text-decoration: underline\">Rakesh</span><span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">: [CONVERSATION] </span>\n",
              "<span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; font-style: italic\">          &gt; What strategies do you use for optimizing deep learning models?</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c92b565bd6fb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mRakesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten_and_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What are your best practices for feature engineering?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mRakesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten_and_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"How do you handle model drift in production systems?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mRakesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten_and_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What strategies do you use for optimizing deep learning models?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Step 4: Create a 2-way Conversation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/control.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mtransaction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_under_transaction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/control.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATUS_STOPPED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# Compute the function and return it, no caching, since the simulation is not started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATUS_STARTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/agent/tiny_person.py\u001b[0m in \u001b[0;36mlisten_and_act\u001b[0;34m(self, speech, return_actions, max_content_length)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_content_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_content_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         return self.act(\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0mreturn_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_content_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_content_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         )\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/control.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mtransaction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_under_transaction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/control.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATUS_STOPPED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# Compute the function and return it, no caching, since the simulation is not started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATUS_STARTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/agent/tiny_person.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, until_done, n, return_actions, max_content_length)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0maux_pre_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                 \u001b[0maux_act_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/utils/llm.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception occurred: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/agent/tiny_person.py\u001b[0m in \u001b[0;36maux_act_once\u001b[0;34m()\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mrepeat_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maux_act_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_produce_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mcognitive_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cognitive_state\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/control.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mtransaction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_under_transaction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/control.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATUS_STOPPED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# Compute the function and return it, no caching, since the simulation is not started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATUS_STARTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/agent/tiny_person.py\u001b[0m in \u001b[0;36m_produce_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{self.name}] Last interaction: {messages[-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mnext_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCognitiveActionModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{self.name}] Received message: {next_message}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/openai_utils.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, current_messages, model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty, stop, timeout, max_attempts, waiting_time, exponential_backoff_factor, n, response_format, echo)\u001b[0m\n\u001b[1;32m    445\u001b[0m                         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaiting_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_model_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_api_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_api_calls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tinytroupe/tinytroupe/openai_utils.py\u001b[0m in \u001b[0;36m_raw_model_call\u001b[0;34m(self, model, chat_api_params)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mchat_api_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             return self.client.beta.chat.completions.parse(\n\u001b[0m\u001b[1;32m    501\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mchat_api_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/beta/chat/completions.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    156\u001b[0m             )\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    920\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    956\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Step 1: Clone the Repository\n",
        "repo_dir = \"tinytroupe\"\n",
        "if os.path.exists(repo_dir):\n",
        "    print(f\"Directory {repo_dir} already exists. Skipping clone.\")\n",
        "else:\n",
        "    subprocess.run([\"git\", \"clone\", \"https://github.com/microsoft/tinytroupe\"])\n",
        "\n",
        "# Navigate to the directory and install\n",
        "os.chdir(repo_dir)\n",
        "subprocess.run([\"pip\", \"install\", \".\"])\n",
        "\n",
        "# Step 2: Set Up Your Environment\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "# Step 3: Create Rakesh, the Data Scientist\n",
        "from tinytroupe.agent import TinyPerson\n",
        "\n",
        "Rakesh = TinyPerson(\"Rakesh\")\n",
        "Rakesh.define(\"age\", 29)\n",
        "Rakesh.define(\"nationality\", \"Indian\")\n",
        "Rakesh.define(\"occupation\", \"Data Scientist\")\n",
        "Rakesh.define(\"professional_history\", \"\"\"\n",
        "Rakesh has experience in data analytics, business intelligence, and machine learning.\n",
        "He has worked on projects involving customer segmentation, financial risk analysis, and predictive modeling.\n",
        "He specializes in Python, SQL, data visualization (Tableau, Power BI), and AI-driven insights.\n",
        "\"\"\")\n",
        "\n",
        "Rakesh.listen_and_act(\"What are the key challenges in deploying machine learning models at scale?\")\n",
        "Rakesh.listen_and_act(\"How do you ensure data quality in large datasets?\")\n",
        "Rakesh.listen_and_act(\"What are your best practices for feature engineering?\")\n",
        "Rakesh.listen_and_act(\"How do you handle model drift in production systems?\")\n",
        "Rakesh.listen_and_act(\"What strategies do you use for optimizing deep learning models?\")\n",
        "\n",
        "# Step 4: Create a 2-way Conversation\n",
        "olivia = TinyPerson(\"Olivia\")\n",
        "olivia.define(\"age\", 30)\n",
        "olivia.define(\"nationality\", \"American\")\n",
        "olivia.define(\"occupation\", \"Cybersecurity Expert\")\n",
        "olivia.define(\"professional_history\", \"\"\"\n",
        "Olivia has spent a decade working in cybersecurity, specializing in ethical hacking and network security.\n",
        "She currently leads a cybersecurity research team focusing on AI-driven threat detection.\n",
        "She has experience in penetration testing, security audits, and cloud security strategies.\n",
        "\"\"\")\n",
        "\n",
        "olivia.listen(\"You want to ask Rakesh about AI's impact on cybersecurity automation.\")\n",
        "olivia.listen(\"You want to ask Rakesh how data science can improve threat intelligence.\")\n",
        "olivia.listen(\"You want to ask Rakesh about handling adversarial attacks in machine learning models.\")\n",
        "olivia.listen(\"You want to ask Rakesh how businesses can leverage AI for fraud detection.\")\n",
        "olivia.listen(\"You want to ask Rakesh about the ethical considerations of AI-driven surveillance.\")\n",
        "\n",
        "# Step 5: Run for 3-5 iterations\n",
        "from tinytroupe.environment import TinyWorld\n",
        "\n",
        "world = TinyWorld(\"AI & Security Forum\", [Rakesh, olivia])\n",
        "world.run(2)\n",
        "world.run(3)\n",
        "world.run(5)\n"
      ]
    }
  ]
}